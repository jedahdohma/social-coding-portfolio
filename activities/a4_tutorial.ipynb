{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cmL8RtM0M9Df0x8ByO2TcPFtAh8ZwZgt",
      "authorship_tag": "ABX9TyNvzAxys41nQXUh3IffksTg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Explain the definition and purpose of the Python script\n",
        "- Gonna split up the screenplay words that can be processed by our computer, excluding character names, screenplay directions, and punctuation marks. We're gonna get the top ten words in the screenplay.\n",
        "2. Key components of the script discussed line by line\n",
        "- I'll include this under.\n",
        "3. A practical example of the Python code in action\n",
        "- This entire thing is practical example.\n"
      ],
      "metadata": {
        "id": "5-J_QFCm4SFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do some text analysis stuff.\n",
        "We're gonna sift through the screenplay for the 1993 sci-fi film Jurassic Park. The text file will be named jp.txt for simplicity. Let's make sure it's available to Colab.\n",
        "\n",
        "First, we have to work with regular expressions. Importing re will do the trick.\n",
        "\n",
        "Also gotta import Counter for our nefarious counting purposes. Capitalize it or else it just won't work.\n",
        "\n"
      ],
      "metadata": {
        "id": "HoxbrgP4IGjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "d6R4d0vRJfLL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to explicitly tell the code what we want to do with the screenplay.\n",
        "\n",
        "We want to make sure that all of the letters are lowercase by using screenplay.lower. We can further refine this information by adding \"\\W+\" so that punctuation marks aren't counted. Keep an eye on indentations since you're defining what split is."
      ],
      "metadata": {
        "id": "MFHuiD4z4Vtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split(screenplay):\n",
        "    lowercase = screenplay.lower()\n",
        "    polished = re.split(\"\\W+\", lowercase)\n",
        "    return polished"
      ],
      "metadata": {
        "id": "SzmQUekE30ir"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we gotta tell it where to find the text file it's going to study. For this test run, let's get the top ten words featured in the script. So we write ten. It's an integer so make sure it doesn't have any quotation marks or whatever around the number.\n"
      ],
      "metadata": {
        "id": "-kSx0WQT3vbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/drive/MyDrive/School/jp.txt\"\n",
        "number = 10"
      ],
      "metadata": {
        "id": "bi76vbP64ZwS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to make sure it doesn't process words that we know are repetitive or bound to appear for sure. Let's also get rid of main character names and stage directions, just to make the count fairer."
      ],
      "metadata": {
        "id": "jSX8fCCk1uZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dontinclude = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
        "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
        " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
        " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
        " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
        " 'did', 'doing', 'a', 'd', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
        " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
        " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
        " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
        " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
        " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
        " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've',\n",
        " 'll', 'amp', 're', 'm', 'cont', 'ext', 'int', 'grant', 'ellie', 'hammond', 'tim', 'lex',\n",
        " 'malcolm', 'nedry', 'muldoon']"
      ],
      "metadata": {
        "id": "1OMXbu0bUbts"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask to read it and specify its encoding."
      ],
      "metadata": {
        "id": "5H4Hj8aEBdDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entirescreenplay = open(filepath, encoding=\"utf-8\").read()"
      ],
      "metadata": {
        "id": "ZNsHGDua0qf6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gotta ask it to split the entire screenplay like we asked for earlier. Use split, you told Python what you mean by splitting. Because we don't want any words in dontinclude, we make sure it accounts for excluding all of those words. Then, we ask how it to count how many instances the screenplay features certain words, excluding the ones we instructed the code to exclude.\n",
        "Finally, we request the top ten most commonly used words."
      ],
      "metadata": {
        "id": "rphBMdPsCprz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allwords = split(entirescreenplay)\n",
        "targetwords = [word for word in allwords if word not in dontinclude]\n",
        "wordstally = Counter(targetwords)\n",
        "top10words = wordstally.most_common(number)\n",
        "top10words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdGIo0IzAgoK",
        "outputId": "f97db59e-8666-484f-b651-83697afdda6b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('back', 182),\n",
              " ('one', 132),\n",
              " ('looks', 119),\n",
              " ('car', 103),\n",
              " ('like', 100),\n",
              " ('look', 98),\n",
              " ('right', 97),\n",
              " ('get', 92),\n",
              " ('day', 86),\n",
              " ('door', 84)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}