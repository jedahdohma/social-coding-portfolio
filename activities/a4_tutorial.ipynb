{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cmL8RtM0M9Df0x8ByO2TcPFtAh8ZwZgt",
      "authorship_tag": "ABX9TyP8Mj33cJ0UMlFMI3XDmkwC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### *Explain the definition and purpose of the Python script:*\n",
        "This script is going to split up the screenplay words that can be processed through Python, **excluding** character names, screenplay directions, and punctuation marks. We're gonna get the top ten words in the screenplay.\n",
        "\n",
        "#### *Key components of the script discussed line by line:*\n",
        "\n",
        "... will be included below.\n",
        "\n",
        "#### *A practical example of the Python code in action:*\n",
        "\n",
        "This entire thing is practical example.\n"
      ],
      "metadata": {
        "id": "5-J_QFCm4SFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do some **text analysis**.\n",
        "We're gonna sift through the screenplay for the 1993 sci-fi film Jurassic Park. The text file will be named **jp.txt** for simplicity. Let's make sure it's available to Colab."
      ],
      "metadata": {
        "id": "HoxbrgP4IGjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we have to work with regular expressions. Importing re will do the trick.\n",
        "import re\n",
        "# Also gotta import Counter for our nefarious counting purposes.\n",
        "# Capitalize it or else it just won't work.\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "d6R4d0vRJfLL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to explicitly tell the code what we want to do with the screenplay."
      ],
      "metadata": {
        "id": "MFHuiD4z4Vtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We tell Python what we mean by split.\n",
        "def split(screenplay):\n",
        "  # We want to make sure that all of the letters are lowercase.\n",
        "    lowercase = screenplay.lower()\n",
        "  # We can further refine this information by adding \"\\W+\" so that punctuation marks aren't counted.\n",
        "    polished = re.split(\"\\W+\", lowercase)\n",
        "  # Keep an eye on indentations since you're defining what split is.\n",
        "    return polished"
      ],
      "metadata": {
        "id": "SzmQUekE30ir"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you've attached your Drive to this, it becomes actually tangible for Python to access."
      ],
      "metadata": {
        "id": "-kSx0WQT3vbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we gotta tell it where to find the text file it's going to study.\n",
        "filepath = \"/content/drive/MyDrive/School/jp.txt\"\n",
        "# For this test run, let's get the top ten words featured in the script.\n",
        "# We write ten. It's an integer so make sure it doesn't have any apostrophes attached.\n",
        "number = 10"
      ],
      "metadata": {
        "id": "bi76vbP64ZwS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to make sure it doesn't process words that we know are repetitive or bound to appear for sure. Let's also get rid of main character names and stage directions, just to make the count fairer."
      ],
      "metadata": {
        "id": "jSX8fCCk1uZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All of these words are just redundant to keep.\n",
        "dontinclude = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
        "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
        " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
        " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
        " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
        " 'did', 'doing', 'a', 'd', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
        " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
        " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
        " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
        " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
        " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
        " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've',\n",
        " 'll', 'amp', 're', 'm', 'cont', 'ext', 'int', 'grant', 'ellie', 'hammond', 'tim', 'lex',\n",
        " 'malcolm', 'nedry', 'muldoon']"
      ],
      "metadata": {
        "id": "1OMXbu0bUbts"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask to read it and specify its encoding."
      ],
      "metadata": {
        "id": "5H4Hj8aEBdDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entirescreenplay = open(filepath, encoding=\"utf-8\").read()"
      ],
      "metadata": {
        "id": "ZNsHGDua0qf6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gotta ask it to split the entire screenplay like we asked for earlier. Use split, you told Python what you mean by splitting. Because we don't want any words in dontinclude, we make sure it accounts for excluding all of those words. Then, we ask how it to count how many instances the screenplay features certain words, excluding the ones we instructed the code to exclude.\n",
        "Finally, we request the top ten most commonly used words."
      ],
      "metadata": {
        "id": "rphBMdPsCprz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the entire screeplay using the way to split that we explained earlier.\n",
        "allwords = split(entirescreenplay)\n",
        "# Making sure that we are excluding the words we don't want.\n",
        "targetwords = [word for word in allwords if word not in dontinclude]\n",
        "# With this, we can count the amount of times certain words are mentioned.\n",
        "wordstally = Counter(targetwords)\n",
        "#Gotta get that top.. 10!\n",
        "top10words = wordstally.most_common(number)\n",
        "# Call that function and get that info you wanted.\n",
        "top10words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdGIo0IzAgoK",
        "outputId": "45593281-db45-4e21-c34c-f627378426a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('back', 182),\n",
              " ('one', 132),\n",
              " ('looks', 119),\n",
              " ('car', 103),\n",
              " ('like', 100),\n",
              " ('look', 98),\n",
              " ('right', 97),\n",
              " ('get', 92),\n",
              " ('day', 86),\n",
              " ('door', 84)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}